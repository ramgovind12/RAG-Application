{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyPDF2 import PdfReader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain_mistralai import ChatMistralAI \n",
    "import psycopg2\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from langchain.vectorstores import PGVector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pdf_content(documents):\n",
    "    # Ensure documents is always treated as a list\n",
    "    if isinstance(documents, str):\n",
    "        documents = [documents]\n",
    "\n",
    "    raw_text = \"\"\n",
    "\n",
    "    for document in documents:\n",
    "        try:\n",
    "            pdf_reader = PdfReader(document)\n",
    "            for page in pdf_reader.pages:\n",
    "                text = page.extract_text()\n",
    "                if text:  # Ensure non-empty text is appended\n",
    "                    raw_text += text\n",
    "        except FileNotFoundError:\n",
    "            print(f\"File not found: {document}\")\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred while processing {document}: {e}\")\n",
    "\n",
    "    return raw_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chunks(text):\n",
    "    text_splitter = CharacterTextSplitter(\n",
    "        separator=\"\\n\",\n",
    "        chunk_size=1000,\n",
    "        chunk_overlap=200,\n",
    "        length_function=len\n",
    "    )\n",
    "    text_chunks = text_splitter.split_text(text)\n",
    "    return text_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(chunks):\n",
    "    # Initialize HuggingFace embeddings using the specified model\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")\n",
    "    \n",
    "    # Create a FAISS vector store from the text chunks and embeddings\n",
    "    vector_storage = FAISS.from_texts(texts=chunks, embedding=embeddings)\n",
    "\n",
    "    return vector_storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(chunks, filepaths):\n",
    "    # Initialize HuggingFace embeddings using the specified model\n",
    "    model = SentenceTransformer(\"sentence-transformers/all-mpnet-base-v2\")\n",
    "    \n",
    "    # Generate embeddings for the text chunks\n",
    "    embeddings = model.encode(chunks)\n",
    "\n",
    "    # Connect to your PostgreSQL database\n",
    "    conn = psycopg2.connect(\n",
    "    host=\"localhost\",  # e.g., \"localhost\"\n",
    "    database=\"postgres\",  # your database name\n",
    "    user=\"postgres\",  # your username\n",
    "    password=\"Govindal@123\"  # your password\n",
    "    )\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # Insert embeddings into the PostgreSQL table\n",
    "    for embedding, textchunk, filepath in zip(embeddings, chunks, filepaths):\n",
    "        # Insert data into the embeddings table\n",
    "        cursor.execute(\"\"\"\n",
    "            INSERT INTO embeddings (embedding, textchunk, filepath)\n",
    "            VALUES (%s, %s, %s);\n",
    "        \"\"\", (embedding.tolist(), textchunk, filepath))  # Convert embedding to list\n",
    "\n",
    "    # Commit the transaction and close the connection\n",
    "    conn.commit()\n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "\n",
    "    print(\"Embeddings inserted successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_conversation(vector_embeddings, query):\n",
    "    # Initialize Mistral AI's LLM (hypothetical)\n",
    "    llm = ChatMistralAI(api_key=\"nR3fP67vOHHPRRK8VD63rQevrewxhjOo\")\n",
    "    \n",
    "    # Set up memory for maintaining conversation history\n",
    "    memory = ConversationBufferMemory(\n",
    "        memory_key='chat_history',\n",
    "        return_messages=True\n",
    "    )\n",
    "    \n",
    "    # Create a conversational retrieval chain\n",
    "    conversation = ConversationalRetrievalChain.from_llm(\n",
    "        llm=llm,\n",
    "        retriever=vector_embeddings.as_retriever(),\n",
    "        memory=memory\n",
    "    )\n",
    "    \n",
    "    # Generate a response for the provided query\n",
    "    response = conversation.run(query)\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = '../data/trump_tariff.pdf'\n",
    "text = get_pdf_content(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = get_chunks(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with the US, and this poli cy shift has rattled global markets , Reuters reports.  \n",
      " \n",
      "Top three trading partners to the US - Mexico, Canada and China. Image: US Census \n",
      "Bureau/Reuters  \n",
      "The Canadian dollar hit a 20 -year low, while the Me xican peso remains volatile, and the euro \n",
      "faces pressure amid fears the European Union is next. However, despite the tariffs, Chinaâ€™s \n",
      "yuan has remained stable.  \n",
      " \n",
      "US futures and foreign currencies fluctuated following tarif f announcements. Image: \n",
      "Reuters/LSEG  \n",
      "The auto sector has also warned of major profit losses, globally but particularly in the US, \n",
      "with analysts cautioning that ongoing uncertainty could slow economic growth and fuel \n",
      "inflation worldwide.  \n",
      "US job growth slowed in January , impacted by weather and wildfires, while economists say a \n",
      "4.0% unemployment rate may delay Federal Reserve rate cuts  until June.  \n",
      "Discover  \n",
      "How is the World Economic Forum improving the global financial system?\n"
     ]
    }
   ],
   "source": [
    "print(chunks[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg2.connect(\n",
    "    host=\"localhost\",  # e.g., \"localhost\"\n",
    "    database=\"postgres\",  # your database name\n",
    "    user=\"postgres\",  # your username\n",
    "    password=\"Govindal@123\"  # your password\n",
    ")\n",
    "cursor = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings inserted successfully.\n"
     ]
    }
   ],
   "source": [
    "get_embeddings(chunks,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
